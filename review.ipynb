{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57411832-737a-43da-a7f3-6ee6e182cc59",
   "metadata": {},
   "source": [
    "## 1. K-최근접 이웃 알고리즘\n",
    "- \"A는 도미일까, 빙어일까? 도미와 빙어의 무게, 길이를 바탕으로 A가 어떤 생선인지 찾는 알고리즘을 만들자.\"\n",
    "- KNeighborsClassifier() 가장 가까운 이웃을 참고하여 정답을 예측하는 알고리즘\n",
    "    - 샘플링 편향이 없는 샘플\n",
    "    - 데이터 전처리: 두 특성의 스케일이 다를 때\n",
    "        - 표준점수: 데이터가 원점에서 몇 표준편차만큼 떨어져 있는지\n",
    " \n",
    "## 2. K-최근접 이웃 회귀\n",
    "- \"농어의 길이, 높이, 두께를 측정한 데이터를 바탕으로 농어의 무게를 맞추자. 정확한 농어의 무게를 측정한 샘플도 있다.\"\n",
    "- KNeighborsRegressor()\n",
    "    - 회귀: 두 변수 사이의 상관관계를 분석. 정해진 클래스가 아닌, 임의의 수치를 출력\n",
    "    - 근접 이웃들의 평균값을 출력\n",
    "    - 과대적합: 훈련 세트에만 맞는 모델, 테스트 세트에서 점수가 낮음\n",
    "    -과소적합\n",
    "\n",
    "## 3. 선형 회귀\n",
    "### 선형 회귀\n",
    "\"샘플들과 차이나는 농어의 무게를 측정하려면, 정확한 무게가 측정되지 않음 (데이터에 크기가 어떻든, 가장 가까운 이웃의 평균을 기준으로 값이 매겨지기 때문) 특성이 하나인 경우 어떤 직선을 학습하는 알고리즘을 만들자.\"\n",
    "LinearRegression\n",
    "y = ax + b (농어 무게 = a * 농어 길이 + b)\n",
    "```\n",
    "lr = LinearRegression()\n",
    "# LinearRegression 클래스가 찾은 a와 b는 lr 객체의 coef_와 intercept_ 속성에 저장\n",
    "```\n",
    "- 모델 기반 학습: 머신러닝을 통해 최적의 모델 파라미터를 찾는 것 (a와 b처럼)\n",
    "- 사례 기반 학습: K-최근접 이웃에는 훈련 세트를 저장하는 것이 훈련의 전부\n",
    "\n",
    "### 다항 회귀\n",
    "\"최적의 곡선(직선X) 찾기\" -> 2차 방정식\n",
    "\n",
    "### 다중 회귀\n",
    "\"더 다양한 특성을 이용하기\" -> 여러 개의 특성을 사용한 선형 회귀\n",
    "PolynomialFeatures 각 특성을 제곱한 항을 추가하고 특성끼리 서로 곱한 항을 추가\n",
    "```\n",
    "poly = PolynomialFeatures(include_bias=False, degree=n)\n",
    "#include_bias는 절편을 위한 특성, degree는 최대 차수\n",
    "poly.fit(train_input)\n",
    "train_poly = poly.transform(train_input)\n",
    "test_poly = poly.transform(test_input)\n",
    "```\n",
    "이 특성들을 활용해 선형 회귀 모델을 훈련, 특성이 너무 많으면 과대 적합됨\n",
    "\n",
    "### 규제\n",
    "\"모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 하자.\"\n",
    "선형 회귀 모델의 경우 특성에 곱해지는 계수(또는 기울기)의 크기를 작게 만드는 일\n",
    "규제를 적용하기 전 정규화가 필요\n",
    "- 정규화\n",
    "StandardScaler\n",
    "```\n",
    "ss = Standardscaler()\n",
    "ss.fit(train_poly)\n",
    "train_scaled = ss.transform(train_poly)\n",
    "test_scaled = ss.transform(test_poly)\n",
    "```\n",
    "- 규제: Ridge와 Lasso를 적용해 스코어 확인하기, alpha가 커질 수록 규제가 커짐 (하이퍼파라미터)\n",
    "```\n",
    "ridge = Ridge(alpha=n)\n",
    "ridge.fit(train_scaled, train_target)\n",
    "ridge.score(train_scaled, train_target)\n",
    "ridge.score(test_scaled, test_target)\n",
    "```\n",
    "\n",
    "## 4-1. 로지스틱 회귀\n",
    "\"랜덤 박스에 들어있는 생선의 크기, 무게, 수가 주어졌을 때, 생선에 대한 확률\"\n",
    "k-최근접이웃분류기: 이웃 클래스의 비율을 확률로 출력, 예를 들어 10개의 이웃 샘플 중 A 클래스가 2개, B 클래스가 5개, C 클래스가 3개라면 샘플 x가 A, B, C일 확률은 각각 20%, ,50%, 30%\n",
    "KNeighborsClassifier의 predict_proba()메서드로 클래스별 확률값 도출\n",
    "--> 이웃 값에 대한 비율이므로 항상 정해진 확률만 출력\n",
    "\n",
    "- 로지스틱 회귀\n",
    "이름은 회귀이지만 (다중) 분류 모델\n",
    "z = a * weight + b * length + c * diagonal + d * height + e * width + f\n",
    "    - 시그모이드 함수: 확률이 되려면 0~1 사이 값이 되어야 함. 각 z가 아주 큰 음수일 때 0이 되고, z가 아주 큰 양수일 때 1이 되도록 바꾸는 함수 (이진 분류)\n",
    "    - 소프트맥스 함수: 여러개의 선형 방정식의 출력값의 합이 1이 되도록 바꾸는 함수 (다중 분류)\n",
    "\n",
    "```\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train, target)\n",
    "\n",
    "# 예측 확률을 반환 (이진 분류 - 샘플마다 음성/양성 클래스에 대한 확률 반환, 다중 분류: 샘플마다 모든 클래스에 대한 확률 반환)\n",
    "lr.predict_proba()\n",
    "\n",
    "# 모델이 학습한 선형 방정식의 출력(=z값)을 반환 (이진 분류 - 양성 클래스의 확률, 다중 분류: 각 클래스마다 선형 방정식을 계산)\n",
    "lr.decision_function()\n",
    "\n",
    "# 소프트 맥스 함수 사용\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "### 4-2. 확률적 경사 하강법\n",
    "- 손실 함수의 경사를 따라 최적의 모델을 찾는 알고리즘\n",
    "- 손실함수: 확률적 경사 하강법이 최적화할 대상\n",
    "- 에포크: 전체 샘플을 모두 사용하는 반복 수\n",
    "    -SGDClassifier 분류\n",
    "    -SGDRegressor 회귀\n",
    "```\n",
    "sc = SGDClassifier(loss='log_loss', max_iter=10, random_state=42)\n",
    "\n",
    "#loss=어떤 함수를 쓸지, max_iter=반복 수\n",
    "\n",
    "sc.partial_fit(train_scaled, train_target) # 방금 학습한 거에 이어서 새로운 학습을 진행한다\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
